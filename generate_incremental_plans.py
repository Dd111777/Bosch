# -*- coding: utf-8 -*-
"""
å¢é‡å®éªŒæ–¹æ¡ˆç”Ÿæˆå™¨ï¼šåŸºäºç»Ÿè®¡åˆ†æç»“æœçš„æ™ºèƒ½é‡‡æ ·
================================================

æ ¹æ®statistical_analysis.xlsxçš„ç»“æœï¼Œç”Ÿæˆ3ç§è§„æ¨¡çš„å®éªŒæ–¹æ¡ˆï¼š
- æ–¹æ¡ˆAï¼š10ä¸ªæ ·æœ¬ï¼ˆÂ¥20ké¢„ç®—ï¼‰
- æ–¹æ¡ˆBï¼š20ä¸ªæ ·æœ¬ï¼ˆÂ¥40ké¢„ç®—ï¼‰
- æ–¹æ¡ˆCï¼š30ä¸ªæ ·æœ¬ï¼ˆÂ¥60ké¢„ç®—ï¼‰

ç­–ç•¥ï¼š
1. è¦†ç›–æ—§æ•°æ®çš„å…³é”®åŒºåŸŸ
2. é¿å¼€æ–°æ•°æ®é›†ä¸­çš„åŒºåŸŸï¼ˆTEMPâ‰ˆ-13, APCâ‰ˆ25ç­‰ï¼‰
3. ä¼˜å…ˆé‡‡æ ·é«˜å˜å¼‚å‚æ•°ï¼ˆCohen's då¤§çš„ï¼‰
4. ç¡®ä¿æ¯ä¸ªå‚æ•°è‡³å°‘æœ‰3ä¸ªä¸åŒæ°´å¹³
"""

import numpy as np
import pandas as pd
from scipy.spatial.distance import cdist

# ============ åŸºäºç»Ÿè®¡åˆ†æçš„å‚æ•°èŒƒå›´ ============
# ä»statistical_analysis.xlsxæå–

PARAM_RANGES = {
    'TEMP': {
        'old_min': -20, 'old_max': 20, 'old_mean': -3.63, 'old_std': 12.85,
        'new_mean': -13.00, 'new_std': 9.36,
        'cohens_d': 2.5,  # é«˜ä¼˜å…ˆçº§
        'importance': 'HIGH'
    },
    'APC': {
        'old_min': 20, 'old_max': 100, 'old_mean': 49.51, 'old_std': 25.99,
        'new_mean': 25.67, 'new_std': 5.59,
        'cohens_d': 5.0,  # æé«˜ä¼˜å…ˆçº§
        'importance': 'CRITICAL'
    },
    'SOURCE_RF': {
        'old_min': 20, 'old_max': 100, 'old_mean': 49.51, 'old_std': 25.99,
        'new_mean': 25.67, 'new_std': 5.59,
        'cohens_d': 5.0,  # æé«˜ä¼˜å…ˆçº§
        'importance': 'CRITICAL'
    },
    'LF_RF': {
        'old_min': 50, 'old_max': 350, 'old_mean': 77.55, 'old_std': 39.35,
        'new_mean': 50.00, 'new_std': 76.10,
        'cohens_d': 4.0,  # é«˜ä¼˜å…ˆçº§
        'importance': 'HIGH'
    },
    'SF6': {
        'old_min': 100, 'old_max': 800, 'old_mean': 410.66, 'old_std': 204.24,
        'new_mean': 320.00, 'new_std': 97.98,
        'cohens_d': 3.5,
        'importance': 'HIGH'
    },
    'C4F8': {
        'old_min': 250, 'old_max': 850, 'old_mean': 448.69, 'old_std': 233.50,
        'new_mean': 331.67, 'new_std': 79.04,
        'cohens_d': 4.5,
        'importance': 'HIGH'
    },
    'DEP_TIME': {
        'old_min': 1.0, 'old_max': 4.0, 'old_mean': 2.04, 'old_std': 1.07,
        'new_mean': 2.01, 'new_std': 0.45,
        'cohens_d': 2.0,
        'importance': 'MEDIUM'
    },
    'ETCH_TIME': {
        'old_min': 1.0, 'old_max': 4.0, 'old_mean': 1.98, 'old_std': 1.10,
        'new_mean': 1.57, 'new_std': 0.85,
        'cohens_d': 1.5,
        'importance': 'MEDIUM'
    }
}

PARAM_NAMES = list(PARAM_RANGES.keys())


# ============ é‡‡æ ·ç­–ç•¥ ============

def generate_strategic_samples(n_samples, strategy='space_filling'):
    """
    ç”Ÿæˆæˆ˜ç•¥æ€§é‡‡æ ·ç‚¹
    
    strategy:
      - 'space_filling': ç©ºé—´å¡«å……ï¼ˆå‡åŒ€è¦†ç›–ï¼‰
      - 'critical_regions': å…³é”®åŒºåŸŸï¼ˆé«˜å˜å¼‚å‚æ•°ï¼‰
      - 'boundary': è¾¹ç•Œæ¢ç´¢ï¼ˆæå€¼ç‚¹ï¼‰
    """
    samples = []
    
    if strategy == 'space_filling':
        # ä½¿ç”¨åˆ†å±‚é‡‡æ ·ç¡®ä¿è¦†ç›–
        # å°†æ¯ä¸ªå‚æ•°åˆ†æˆ3-5ä¸ªåŒºé—´
        
        # ç¡®å®šæ¯ä¸ªå‚æ•°çš„é‡‡æ ·æ°´å¹³
        n_levels = max(3, int(np.ceil(n_samples ** (1/8))))  # 8ä¸ªå‚æ•°
        
        # ç”Ÿæˆç½‘æ ¼ç‚¹ï¼ˆä½†ä¸æ˜¯å…¨å› å­ï¼Œè€Œæ˜¯Sobolåºåˆ—ï¼‰
        from scipy.stats import qmc
        sampler = qmc.Sobol(d=8, scramble=True, seed=42)
        samples_normalized = sampler.random(n=n_samples * 10)  # ç”Ÿæˆ10å€å€™é€‰
        
        # ç¼©æ”¾åˆ°å®é™…èŒƒå›´
        samples_real = []
        for sample in samples_normalized:
            recipe = {}
            for i, param in enumerate(PARAM_NAMES):
                prange = PARAM_RANGES[param]
                # ä½¿ç”¨5%-95%åˆ†ä½æ•°èŒƒå›´ï¼ˆé¿å…æå€¼ï¼‰
                low = prange['old_min'] + 0.05 * (prange['old_max'] - prange['old_min'])
                high = prange['old_max'] - 0.05 * (prange['old_max'] - prange['old_min'])
                recipe[param] = low + sample[i] * (high - low)
            samples_real.append(recipe)
        
        # è®¡ç®—åˆ°æ–°æ•°æ®ä¸­å¿ƒçš„è·ç¦»ï¼Œé€‰æ‹©æœ€è¿œçš„n_samplesä¸ª
        new_center = np.array([PARAM_RANGES[p]['new_mean'] for p in PARAM_NAMES])
        
        # æ ‡å‡†åŒ–
        samples_array = np.array([[s[p] for p in PARAM_NAMES] for s in samples_real])
        scales = np.array([PARAM_RANGES[p]['old_std'] for p in PARAM_NAMES])
        samples_normalized = (samples_array - new_center) / scales
        
        # è®¡ç®—è·ç¦»
        distances = np.linalg.norm(samples_normalized, axis=1)
        
        # é€‰æ‹©æœ€è¿œçš„n_samplesä¸ª
        selected_idx = np.argsort(distances)[-n_samples:]
        samples = [samples_real[i] for i in selected_idx]
    
    elif strategy == 'critical_regions':
        # é‡ç‚¹é‡‡æ ·å…³é”®å‚æ•°ï¼ˆCohen's då¤§çš„ï¼‰
        critical_params = [p for p in PARAM_NAMES if PARAM_RANGES[p]['importance'] in ['CRITICAL', 'HIGH']]
        
        # å¯¹å…³é”®å‚æ•°ä½¿ç”¨3æ°´å¹³ï¼Œå…¶ä»–å‚æ•°ä½¿ç”¨å‡å€¼
        levels = [-1, 0, 1]  # ä½ã€ä¸­ã€é«˜
        
        for i in range(n_samples):
            recipe = {}
            for param in PARAM_NAMES:
                prange = PARAM_RANGES[param]
                
                if param in critical_params:
                    # éšæœºé€‰æ‹©ä¸€ä¸ªæ°´å¹³
                    level = np.random.choice(levels)
                    if level == -1:
                        recipe[param] = prange['old_min'] + 0.1 * (prange['old_max'] - prange['old_min'])
                    elif level == 0:
                        recipe[param] = prange['old_mean']
                    else:
                        recipe[param] = prange['old_max'] - 0.1 * (prange['old_max'] - prange['old_min'])
                else:
                    # ä½¿ç”¨å‡å€¼ Â± éšæœºæ‰°åŠ¨
                    recipe[param] = prange['old_mean'] + np.random.randn() * prange['old_std'] * 0.5
                    # è£å‰ªåˆ°èŒƒå›´å†…
                    recipe[param] = np.clip(recipe[param], prange['old_min'], prange['old_max'])
            
            samples.append(recipe)
    
    elif strategy == 'boundary':
        # æ¢ç´¢è¾¹ç•Œå’Œè§’ç‚¹
        # 2^8 = 256ä¸ªè§’ç‚¹å¤ªå¤šï¼Œé€‰æ‹©å…³é”®çš„
        
        # å¯¹æ¯ä¸ªå‚æ•°ï¼Œäº¤æ›¿ä½¿ç”¨é«˜ä½å€¼
        for i in range(n_samples):
            recipe = {}
            np.random.seed(42 + i)
            
            for param in PARAM_NAMES:
                prange = PARAM_RANGES[param]
                
                # 70%æ¦‚ç‡é€‰æ‹©è¾¹ç•Œï¼Œ30%æ¦‚ç‡é€‰æ‹©ä¸­é—´
                if np.random.rand() < 0.7:
                    # è¾¹ç•Œå€¼ï¼ˆé«˜æˆ–ä½ï¼‰
                    if np.random.rand() < 0.5:
                        recipe[param] = prange['old_min'] + 0.05 * (prange['old_max'] - prange['old_min'])
                    else:
                        recipe[param] = prange['old_max'] - 0.05 * (prange['old_max'] - prange['old_min'])
                else:
                    # ä¸­é—´å€¼
                    recipe[param] = prange['old_mean']
            
            samples.append(recipe)
    
    return samples


def optimize_sample_diversity(samples):
    """ä¼˜åŒ–æ ·æœ¬å¤šæ ·æ€§ï¼šç¡®ä¿æ¯ä¸ªå‚æ•°æœ‰å¤šä¸ªæ°´å¹³"""
    # æ£€æŸ¥æ¯ä¸ªå‚æ•°çš„å”¯ä¸€å€¼æ•°é‡
    df = pd.DataFrame(samples)
    
    for param in PARAM_NAMES:
        unique_values = df[param].nunique()
        if unique_values < 3:
            print(f"  âš  {param} only has {unique_values} unique values, adding diversity...")
            # å¼ºåˆ¶æ·»åŠ ä¸åŒæ°´å¹³
            prange = PARAM_RANGES[param]
            levels = [
                prange['old_min'] + 0.1 * (prange['old_max'] - prange['old_min']),
                prange['old_mean'],
                prange['old_max'] - 0.1 * (prange['old_max'] - prange['old_min'])
            ]
            
            # æ›¿æ¢å‰3ä¸ªæ ·æœ¬
            for i in range(min(3, len(samples))):
                samples[i][param] = levels[i % 3]
    
    return samples


def round_to_practical_values(samples):
    """èˆå…¥åˆ°å®é™…å¯æ“ä½œçš„å€¼"""
    for sample in samples:
        # æ¸©åº¦ï¼šæ•´æ•°
        sample['TEMP'] = round(sample['TEMP'])
        
        # APC, SOURCE_RF, LF_RF: 5çš„å€æ•°
        sample['APC'] = round(sample['APC'] / 5) * 5
        sample['SOURCE_RF'] = round(sample['SOURCE_RF'] / 5) * 5
        sample['LF_RF'] = round(sample['LF_RF'] / 5) * 5
        
        # SF6, C4F8: 10çš„å€æ•°
        sample['SF6'] = round(sample['SF6'] / 10) * 10
        sample['C4F8'] = round(sample['C4F8'] / 10) * 10
        
        # æ—¶é—´: 0.1ç²¾åº¦
        sample['DEP_TIME'] = round(sample['DEP_TIME'], 1)
        sample['ETCH_TIME'] = round(sample['ETCH_TIME'], 1)
    
    return samples


def prioritize_samples(samples, current_data_mean):
    """æ ¹æ®è·ç¦»å½“å‰æ•°æ®çš„è¿œè¿‘æ’åºï¼ˆè¿œçš„ä¼˜å…ˆçº§é«˜ï¼‰"""
    samples_array = np.array([[s[p] for p in PARAM_NAMES] for s in samples])
    current_array = np.array([current_data_mean[p] for p in PARAM_NAMES])
    
    # æ ‡å‡†åŒ–
    scales = np.array([PARAM_RANGES[p]['old_std'] for p in PARAM_NAMES])
    samples_normalized = (samples_array - current_array) / scales
    
    # è®¡ç®—è·ç¦»
    distances = np.linalg.norm(samples_normalized, axis=1)
    
    # æ’åºï¼ˆè·ç¦»å¤§çš„æ’å‰é¢ï¼‰
    sorted_idx = np.argsort(distances)[::-1]
    
    return [samples[i] for i in sorted_idx], distances[sorted_idx]


# ============ ç”Ÿæˆ3ä¸ªæ–¹æ¡ˆ ============

def main():
    print("="*80)
    print("å¢é‡å®éªŒæ–¹æ¡ˆç”Ÿæˆå™¨ï¼ˆåŸºäºç»Ÿè®¡åˆ†æç»“æœï¼‰")
    print("="*80)
    
    # å½“å‰æ–°æ•°æ®çš„ä¸­å¿ƒ
    current_center = {p: PARAM_RANGES[p]['new_mean'] for p in PARAM_NAMES}
    
    # ç”Ÿæˆ3ä¸ªæ–¹æ¡ˆ
    plans = {}
    
    for n in [10, 20, 30]:
        print(f"\n{'='*80}")
        print(f"æ–¹æ¡ˆ{chr(64+n//10)}: {n}ä¸ªæ–°æ ·æœ¬")
        print(f"{'='*80}")
        
        # æ··åˆç­–ç•¥
        # 70%ç©ºé—´å¡«å…… + 30%å…³é”®åŒºåŸŸ
        n_space = int(n * 0.7)
        n_critical = n - n_space
        
        samples_space = generate_strategic_samples(n_space, strategy='space_filling')
        samples_critical = generate_strategic_samples(n_critical, strategy='critical_regions')
        
        samples = samples_space + samples_critical
        
        # ä¼˜åŒ–å¤šæ ·æ€§
        samples = optimize_sample_diversity(samples)
        
        # èˆå…¥åˆ°å®é™…å€¼
        samples = round_to_practical_values(samples)
        
        # æ’åºï¼ˆä¼˜å…ˆçº§ï¼‰
        samples, distances = prioritize_samples(samples, current_center)
        
        # æ·»åŠ ä¼˜å…ˆçº§å’Œé¢„æœŸä¿¡æ¯å¢ç›Š
        df = pd.DataFrame(samples)
        df.insert(0, 'Sample_ID', [f'EXP_{i+1:03d}' for i in range(len(df))])
        df.insert(1, 'Priority', ['HIGH']*5 + ['MEDIUM']*10 + ['LOW']*(n-15) if n>=15 else ['HIGH']*n)
        df.insert(2, 'Distance_from_Current', distances)
        df['Expected_Info_Gain'] = (distances / distances.max() * 100).astype(int)
        
        # æ·»åŠ æ¨èçš„é‡å¤æ¬¡æ•°
        df['Recommended_Replicates'] = 2
        df['Notes'] = ''
        
        # æ ‡è®°å…³é”®å®éªŒ
        df.loc[df['Priority'] == 'HIGH', 'Notes'] = 'ä¼˜å…ˆæ‰§è¡Œï¼Œé«˜ä¿¡æ¯å¢ç›Š'
        df.loc[df['Priority'] == 'MEDIUM', 'Notes'] = 'æ¬¡ä¼˜å…ˆï¼Œè¦†ç›–è¡¥å……'
        df.loc[df['Priority'] == 'LOW', 'Notes'] = 'å¯é€‰ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–'
        
        plans[f'Plan_{n}samples'] = df
        
        print(f"\n  âœ“ Generated {n} samples")
        print(f"  âœ“ Average distance from current data: {distances.mean():.2f} Ïƒ")
        print(f"  âœ“ Max distance: {distances.max():.2f} Ïƒ")
        print(f"  âœ“ Min distance: {distances.min():.2f} Ïƒ")
        
        # æ˜¾ç¤ºå‚æ•°è¦†ç›–æƒ…å†µ
        print(f"\n  Parameter coverage:")
        for param in PARAM_NAMES:
            vals = df[param].values
            print(f"    {param:12s}: [{vals.min():.1f}, {vals.max():.1f}]  "
                  f"(n_unique={df[param].nunique()})")
    
    # ä¿å­˜åˆ°Excel
    output_file = './incremental_experiment_plans.xlsx'
    
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # å†™å…¥å„ä¸ªæ–¹æ¡ˆ
        for plan_name, df in plans.items():
            sheet_name = plan_name.replace('Plan_', '').replace('samples', 'S')
            df.to_excel(writer, sheet_name=sheet_name, index=False)
        
        # å†™å…¥è¯´æ˜
        summary_data = {
            'æ–¹æ¡ˆ': ['Plan A (10ä¸ª)', 'Plan B (20ä¸ª)', 'Plan C (30ä¸ª)'],
            'æ€»å®éªŒæ•°': [10, 20, 30],
            'æ¨èé‡å¤': [2, 2, 2],
            'æ€»è¿è¡Œæ•°': [20, 40, 60],
            'é¢„ä¼°æˆæœ¬(Â¥)': [20000, 40000, 60000],
            'é¢„ä¼°æ—¶é—´(å°æ—¶)': [40, 80, 120],
            'é¢„ä¼°æ—¶é—´(å¤©)': [2, 3, 5],
            'é¢„æœŸRÂ²æå‡': ['0.3-0.5', '0.5-0.7', '0.6-0.8'],
            'æ¨èåœºæ™¯': ['é¢„ç®—ç´§å¼ ï¼Œå¿«é€ŸéªŒè¯', 'å¹³è¡¡æ–¹æ¡ˆï¼Œæ¨è', 'å……åˆ†è¦†ç›–ï¼Œæœ€ä½³æ•ˆæœ']
        }
        summary_df = pd.DataFrame(summary_data)
        summary_df.to_excel(writer, sheet_name='Summary', index=False)
        
        # å†™å…¥å‚æ•°èŒƒå›´å‚è€ƒ
        ranges_data = []
        for param in PARAM_NAMES:
            prange = PARAM_RANGES[param]
            ranges_data.append({
                'Parameter': param,
                'Old_Min': prange['old_min'],
                'Old_Max': prange['old_max'],
                'Old_Mean': prange['old_mean'],
                'Old_Std': prange['old_std'],
                'New_Mean': prange['new_mean'],
                'New_Std': prange['new_std'],
                'Cohens_d': prange['cohens_d'],
                'Importance': prange['importance'],
                'Recommended_Levels': f"[{prange['old_min']}, {prange['old_mean']:.0f}, {prange['old_max']}]"
            })
        ranges_df = pd.DataFrame(ranges_data)
        ranges_df.to_excel(writer, sheet_name='Parameter_Ranges', index=False)
    
    print(f"\n{'='*80}")
    print(f"âœ… All plans saved to: {output_file}")
    print(f"{'='*80}")
    
    # æ‰“å°æ¨è
    print(f"\nğŸ“‹ RECOMMENDATIONS:")
    print(f"\nğŸ¥‡ å¦‚æœé¢„ç®—å……è¶³ï¼ˆÂ¥60kï¼‰ï¼š")
    print(f"   â†’ ä½¿ç”¨ Plan C (30ä¸ªæ ·æœ¬)")
    print(f"   â†’ é¢„æœŸRÂ²å¯è¾¾ 0.6-0.8")
    print(f"   â†’ å…¨é¢è¦†ç›–å‚æ•°ç©ºé—´")
    
    print(f"\nğŸ¥ˆ å¦‚æœé¢„ç®—é€‚ä¸­ï¼ˆÂ¥40kï¼‰ï¼š")
    print(f"   â†’ ä½¿ç”¨ Plan B (20ä¸ªæ ·æœ¬) â­ æ¨è")
    print(f"   â†’ é¢„æœŸRÂ²å¯è¾¾ 0.5-0.7")
    print(f"   â†’ æ€§ä»·æ¯”æœ€ä¼˜")
    
    print(f"\nğŸ¥‰ å¦‚æœé¢„ç®—ç´§å¼ ï¼ˆÂ¥20kï¼‰ï¼š")
    print(f"   â†’ ä½¿ç”¨ Plan A (10ä¸ªæ ·æœ¬)")
    print(f"   â†’ é¢„æœŸRÂ²å¯è¾¾ 0.3-0.5")
    print(f"   â†’ å¿«é€ŸéªŒè¯å¯è¡Œæ€§")
    
    print(f"\nğŸ’¡ åˆ†é˜¶æ®µç­–ç•¥ï¼ˆæ¨èï¼‰ï¼š")
    print(f"   1. å…ˆæ‰§è¡ŒPlan Açš„10ä¸ªHIGH priorityæ ·æœ¬")
    print(f"   2. è®­ç»ƒè¯„ä¼°ï¼Œå¦‚æœRÂ²>0.3ï¼Œç»§ç»­")
    print(f"   3. è¡¥å……Plan Bçš„å¦å¤–10ä¸ªæ ·æœ¬")
    print(f"   4. å†æ¬¡è¯„ä¼°ï¼Œå†³å®šæ˜¯å¦æ‰§è¡ŒPlan C")
    
    print(f"\nğŸ”¬ æ‰§è¡Œå»ºè®®ï¼š")
    print(f"   1. æ‰“å¼€Excelæ–‡ä»¶çš„å¯¹åº”sheet")
    print(f"   2. ä¼˜å…ˆæ‰§è¡ŒPriority=HIGHçš„æ ·æœ¬")
    print(f"   3. æ¯ä¸ªæ ·æœ¬é‡å¤2æ¬¡æµ‹é‡")
    print(f"   4. éšæœºåŒ–æ‰§è¡Œé¡ºåºï¼ˆé˜²æ­¢ç³»ç»Ÿè¯¯å·®ï¼‰")
    print(f"   5. è®°å½•æ‰€æœ‰å‚æ•°è®¾ç½®å’Œæµ‹é‡ç»“æœ")
    
    print(f"\n{'='*80}")
    
    # æ˜¾ç¤ºå‰5ä¸ªæ ·æœ¬é¢„è§ˆ
    print(f"\nğŸ“Š Plan B (20 samples) - Top 5 Preview:")
    print(f"{'='*80}")
    df_preview = plans['Plan_20samples'].head(5)
    print(df_preview[['Sample_ID', 'Priority', 'TEMP', 'APC', 'SOURCE_RF', 'LF_RF', 'Expected_Info_Gain']].to_string(index=False))
    print(f"\n  (See full table in Excel file)")
    
    return plans


if __name__ == "__main__":
    main()
